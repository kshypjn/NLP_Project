{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9TBilnuGav1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import ast\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/NLP_Fashionpedia\")\n",
        "IMG_DIR = BASE_DIR / \"train_sample\"\n",
        "ATTR_CSV = BASE_DIR / \"train_attribute_data.csv\"\n",
        "CHECKPOINT_DIR = BASE_DIR / \"checkpoints\"\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjnQy5OjGjWj",
        "outputId": "b2770d65-bd03-4786-bfc9-46dd32c94ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionAttrDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        # Convert the string representation of the attribute list into an actual list\n",
        "        self.df[\"attributes\"] = self.df[\"attributes\"].apply(ast.literal_eval)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / f\"{row.image_id}.jpg\"\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(row.attributes, dtype=torch.float32)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "ruFnK-e3Gkkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms (ResNet-50 expects 224x224 images, normalized with ImageNet stats)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create the dataset using the CSV with attribute data and the image directory.\n",
        "dataset = FashionAttrDataset(ATTR_CSV, IMG_DIR, transform)\n",
        "print(\"Total samples in dataset:\", len(dataset))"
      ],
      "metadata": {
        "id": "6pRpLSgQGlv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fad9d4f-e0d5-4112-a0aa-87ea6515fc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples in dataset: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training (80%) and validation (20%) subsets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n"
      ],
      "metadata": {
        "id": "y91vNg19GnGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4612f67-4ee0-417f-fe1a-3f07fc07c933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 1600\n",
            "Validation samples: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader objects (use num_workers=0 to avoid multiprocessing pickling issues in Colab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n"
      ],
      "metadata": {
        "id": "obf-gohFGoUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of attributes from one sample.\n",
        "num_attributes = len(dataset.df.iloc[0][\"attributes\"])\n",
        "print(\"Number of attributes:\", num_attributes)\n",
        "\n",
        "# Load ResNet-50 pre-trained on ImageNet\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Replace the final FC layer to output 'num_attributes' predictions (for multi-label classification)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_attributes)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "6dh1kTt7G0YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2f016d-40cb-423d-a49c-905ca383e284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of attributes: 294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 30\n",
        "patience = 5  # Early stopping patience (number of epochs to wait for improvement)\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss = validate(model, val_loader, criterion)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Early stopping: if validation loss improves, save the model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        epochs_no_improve = 0\n",
        "        print(\"Validation loss improved, model saved.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "total_training_time = time.time() - start_time\n",
        "print(f\"Total training time: {total_training_time/60:.2f} minutes\")\n"
      ],
      "metadata": {
        "id": "WJtW5BcKG1xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1035ab8-3449-4ef2-dbc1-de76a7af4539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | Train Loss: 0.1644 | Val Loss: 0.0824 | Time: 1664.58s\n",
            "Validation loss improved, model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 | Train Loss: 0.0799 | Val Loss: 0.0762 | Time: 182.34s\n",
            "Validation loss improved, model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 | Train Loss: 0.0725 | Val Loss: 0.0743 | Time: 182.83s\n",
            "Validation loss improved, model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 | Train Loss: 0.0672 | Val Loss: 0.0737 | Time: 184.77s\n",
            "Validation loss improved, model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 | Train Loss: 0.0618 | Val Loss: 0.0732 | Time: 183.52s\n",
            "Validation loss improved, model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 | Train Loss: 0.0565 | Val Loss: 0.0739 | Time: 182.85s\n",
            "No improvement for 1 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 | Train Loss: 0.0516 | Val Loss: 0.0742 | Time: 182.03s\n",
            "No improvement for 2 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 | Train Loss: 0.0470 | Val Loss: 0.0748 | Time: 183.96s\n",
            "No improvement for 3 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 | Train Loss: 0.0421 | Val Loss: 0.0754 | Time: 183.21s\n",
            "No improvement for 4 epoch(s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 | Train Loss: 0.0380 | Val Loss: 0.0756 | Time: 184.62s\n",
            "No improvement for 5 epoch(s).\n",
            "Early stopping triggered.\n",
            "Total training time: 55.26 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_path = BASE_DIR / \"resnet50_NLP_attributes_final.pth\"\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"Model saved to {final_model_path}\")\n"
      ],
      "metadata": {
        "id": "qPHNEZXCG7mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e50575-c210-4eb7-b530-5037658f568e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/NLP_Fashionpedia/resnet50_NLP_attributes_final.pth\n"
          ]
        }
      ]
    }
  ]
}